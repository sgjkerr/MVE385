{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 8301 data from ./data/data_validation.hdf5\n",
      "MolNet_MS(\n",
      "  (encoder): Encoder(\n",
      "    (hidden_layers): ModuleList(\n",
      "      (0): MolConv k = 6 (15 -> 64)\n",
      "      (1): MolConv k = 6 (64 -> 64)\n",
      "      (2): MolConv k = 6 (64 -> 128)\n",
      "      (3): MolConv k = 6 (128 -> 256)\n",
      "      (4): MolConv k = 6 (256 -> 512)\n",
      "      (5): MolConv k = 6 (512 -> 1024)\n",
      "    )\n",
      "    (conv): Sequential(\n",
      "      (0): Conv1d(2048, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (merge): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): MSDecoder(\n",
      "    (blocks): ModuleList(\n",
      "      (0-6): 7 x FCResBlock (2048 -> 2048)\n",
      "    )\n",
      "    (fc): Linear(in_features=2048, out_features=171, bias=True)\n",
      "  )\n",
      ") #Params: 101815277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 8301/8301 [04:03<00:00, 34.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01795123675512785 0.017595261302713446\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import pickle\n",
    "from pyteomics import mgf\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "# ignore the warning\n",
    "from rdkit import RDLogger \n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "from molmspack.molnet import MolNet_Oth, MolNet_MS\n",
    "from molmspack.dataset import MolORNL_Dataset_For_Ploting\n",
    "from molmspack.data_utils import csv2pkl_wfilter, mgf2pkl_wfilter, nce2ce, precursor_calculator\n",
    "\n",
    "import h5py\n",
    "from draw_spectra import draw_spectrum_direct\n",
    "\n",
    "model_str = '3DMolMS_MSE'\n",
    "data_type = 'validation'\n",
    "normalization = 'MAX'\n",
    "small_true = False\n",
    "save_data_bool = False\n",
    "\n",
    "if small_true:\n",
    "    end_str_1 = '_small.hdf5'\n",
    "    end_str_2 = '_small.csv'\n",
    "else:\n",
    "    end_str_1 = '.hdf5'\n",
    "    end_str_2 = '.csv'\n",
    "\n",
    "args = argparse.Namespace(\n",
    "\ttest_data='./data/data_'+ data_type + end_str_1,\n",
    "\tsave_pkl=True,\n",
    "\tmodel_config_path='./config/molnet.yml',\n",
    "\tdata_config_path='./config/preprocess_uv-vis.yml',\n",
    "\tresume_path='./check_point/molnet_uv-vis_from_start_max_norm_transfer_p_2.pt',\n",
    "\tresult_path='./check_point/predictions/'+ data_type +'/pred'+ end_str_2,\n",
    "\ttrue_output='y',\n",
    "\tseed=42,\n",
    "\tdevice=0,\n",
    "\tno_cuda=False\n",
    ")\n",
    "with open(args.model_config_path, 'r') as f: \n",
    "\tconfig = yaml.load(f, Loader=yaml.FullLoader)\n",
    "spectrum_discretization_step = config['model']['resolution']\n",
    "xmin_spectrum = config['model']['min_wavelength']\n",
    "xmax_spectrum = config['model']['max_wavelength'] + spectrum_discretization_step\n",
    "w = 10\n",
    "\n",
    "\n",
    "def gauss_torch(a, m, x, w, log_2):\n",
    "    # calculation of the Gaussian line shape\n",
    "    # a = amplitude (max y, intensity)\n",
    "    # x = position\n",
    "    # m = maximum/median (stick position in x, wave number)\n",
    "    # w = line width, FWHM\n",
    "\te = torch.exp(-(log_2 * ((m-x) / w) ** 2))\n",
    "\treturn torch.einsum('i,ij->ij', a, e)\n",
    "\n",
    "\n",
    "def pred_step(model, device, loader, batch_size, num_points): \n",
    "\tmodel.eval()\n",
    "\tdict_pred = {}\n",
    "\taccuracy = []\n",
    "\n",
    "\tbins = int((xmax_spectrum - xmin_spectrum)/spectrum_discretization_step)\n",
    "\tx_spectra_cpu = np.arange(xmin_spectrum, xmax_spectrum, spectrum_discretization_step)\n",
    "\tx_spectra = torch.arange(xmin_spectrum, xmax_spectrum, spectrum_discretization_step, device=device)\n",
    "\tx_spectra_tensor = x_spectra.unsqueeze(0)  # Add an extra dimension at the beginning\n",
    "\tx_spectra_tensor = x_spectra_tensor.repeat(batch_size, 1)\n",
    "\tlog_2 = torch.log(torch.tensor(2.0, device=device))\n",
    "\twith tqdm(total=len(loader)) as bar:\n",
    "\t\tfor step, batch in enumerate(loader):\n",
    "\t\t\ttitle, smiles, x, y = batch\n",
    "\t\t\tx = x.to(device=device, dtype=torch.float)\n",
    "\t\t\tx = x.permute(0, 2, 1)\n",
    "\t\t\ty = y.to(device=device, dtype=torch.float)\n",
    "\t\t\tif normalization == 'MAX':\n",
    "\t\t\t\ty = y / torch.max(y, dim=1, keepdim=True)[0]\n",
    "\t\t\telif normalization == 'SUM':\n",
    "\t\t\t\ty = y / torch.sum(y, dim=1, keepdim=True)\n",
    "\t\t\t#env = torch.arange().to(device=device, dtype=torch.float)\n",
    "\t\t\tidx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1) * num_points\n",
    "\n",
    "\t\t\twith torch.no_grad(): \n",
    "\t\t\t\tpred = model(x, None, idx_base)\n",
    "\t\t\t\tpred = nn.LeakyReLU(0.1)(pred)\n",
    "\n",
    "\t\t\tgauss_sum = torch.zeros((batch_size, bins), dtype=torch.float, device=device)  \n",
    "\t\t\tfor index, wn in enumerate(x_spectra):\n",
    "\t\t\t\tgauss_sum += gauss_torch(pred[:,index], x_spectra_tensor, wn, w, log_2)\n",
    "\t\t\tif normalization == 'MAX':\n",
    "\t\t\t\tgauss_sum = gauss_sum / torch.max(gauss_sum, dim=1, keepdim=True)[0]\n",
    "\t\t\telif normalization == 'SUM':\n",
    "\t\t\t\tgauss_sum = gauss_sum / torch.sum(gauss_sum, dim=1, keepdim=True)\n",
    "\t\t\tgauss_sum = torch.pow(gauss_sum, 2)\n",
    "\t\t\tbar.set_description('Eval')\n",
    "\t\t\tbar.update(1)\n",
    "\t\t\t# For each mini-batch step in batch, draw the predictions and ground truth\n",
    "\t\t\t# Flatten batch\n",
    "\t\t\tscore = nn.MSELoss()(gauss_sum, y).cpu().numpy().item()\n",
    "\t\t\taccuracy.append(score)\n",
    "\t\t\t#Plot every 100 steps\n",
    "\t\t\ty = y / torch.max(y, dim=1, keepdim=True)[0]\n",
    "\t\t\tgauss_sum = gauss_sum / torch.max(gauss_sum, dim=1, keepdim=True)[0]\n",
    "\t\t\tfor i in range(batch_size):\n",
    "\t\t\t\tpred_tmp = pred[i,:].cpu().numpy()\n",
    "\t\t\t\tgauss_sum_tmp = gauss_sum[i,:].cpu().numpy()\n",
    "\t\t\t\ty_tmp = y[i,:].cpu().numpy()\n",
    "\t\t\t\tstep_size = y_tmp.shape[0]\n",
    "\t\t\t\tfor idx, intensity in enumerate(gauss_sum_tmp):\n",
    "\t\t\t\t\ty_save = y_tmp[idx]\n",
    "\t\t\t\t\tsmiles_tmp = smiles[0]\n",
    "\t\t\t\t\tgroup_id = model_str + '_' + smiles_tmp + '_' + normalization\n",
    "\t\t\t\t\twavelength_tmp = x_spectra_cpu[idx]\n",
    "\t\t\t\t\tdict_pred[step*step_size + idx] = [model_str, title[0], smiles_tmp, wavelength_tmp, intensity, y_save, group_id]\n",
    "    \n",
    "    \n",
    "\t\t\t\tif not save_data_bool:\n",
    "\t\t\t\t\tdraw_spectrum_direct(gauss_sum_tmp/np.max(gauss_sum_tmp),\n",
    "                          y_tmp/np.max(y_tmp), str(i),\n",
    "                          max_wavelength=xmax_spectrum, \n",
    "                          min_wavelength=xmin_spectrum, \n",
    "                          resolution=spectrum_discretization_step)\n",
    "\t\t\tif not save_data_bool:\n",
    "\t\t\t\tif step == 5:\n",
    "\t\t\t\t\treturn dict_pred, accuracy\n",
    "\treturn dict_pred, accuracy\n",
    "\n",
    "def init_random_seed(seed):\n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\treturn\n",
    "\n",
    "\n",
    "init_random_seed(args.seed)\n",
    "\n",
    "\n",
    "with open(args.model_config_path, 'r') as f: \n",
    "\tconfig = yaml.load(f, Loader=yaml.FullLoader)\n",
    "print('Load the model & training configuration from {}'.format(args.model_config_path))\n",
    "with open(args.data_config_path, 'r') as f: \n",
    "\tdata_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "print('Load the data configuration from {}'.format(args.data_config_path))\n",
    "\n",
    "\n",
    "valid_set = MolORNL_Dataset_For_Ploting(args.test_data, args.true_output, data_augmentation=False, partitioned=False)\n",
    "valid_loader = DataLoader(\n",
    "\t\t\t\tvalid_set,\n",
    "\t\t\t\tbatch_size=1, \n",
    "\t\t\t\tshuffle=False, \n",
    "\t\t\t\tnum_workers=config['train']['num_workers'], \n",
    "\t\t\t\tdrop_last=True)\n",
    "\n",
    "# 2. Model\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = MolNet_MS(config['model']).to(device)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{str(model)} #Params: {num_params}')\n",
    "\n",
    "# 3. Evaluation\n",
    "print(\"Load the checkpoints...\")\n",
    "model.load_state_dict(torch.load(args.resume_path, map_location=device)['model_state_dict'])\n",
    "\n",
    "dict_pred, accuracy = pred_step(model, device, valid_loader, \n",
    "          batch_size=1, num_points=config['model']['max_atom_num'])\n",
    "accuracy = np.array(accuracy)\n",
    "\n",
    "print(np.mean(accuracy), np.std(accuracy))\n",
    "if save_data_bool:\n",
    "\n",
    "\t# Write the dict_pred to csv file\n",
    "\tdf_pred = pd.DataFrame.from_dict(dict_pred, orient='index', columns=['model', 'title', 'smiles', 'nm', 'pred', 'y', 'group_id'])\n",
    "\tdf_pred.to_csv(args.result_path, index=False)\n",
    "\tdisplay(df_pred.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
